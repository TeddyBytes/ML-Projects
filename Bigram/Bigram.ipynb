{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open training data\n",
    "with open(f\"./names.txt\") as file:\n",
    "    words = file.readlines()\n",
    "    \n",
    "# Make list of each word from data\n",
    "words = [word.strip() for word in words]\n",
    "\n",
    "# store alphabet of letters from data. \n",
    "alphabet = set()\n",
    "alphabet.add('<S>')\n",
    "alphabet.add('<E>')\n",
    "\n",
    "for word in words:\n",
    "    for char in word:\n",
    "        alphabet.add(char)\n",
    "\n",
    "\n",
    "# Store alphabet to index mapping with reverse functionality. \n",
    "alphabet = list(alphabet)\n",
    "alphabet = sorted(alphabet)\n",
    "char_to_int = dict()\n",
    "int_to_char = dict()\n",
    "\n",
    "for index, char in enumerate(alphabet):\n",
    "    char_to_int[char] = index\n",
    "    int_to_char[index] = char\n",
    "\n",
    "# Store token counts\n",
    "token_counts = dict()\n",
    "\n",
    "# Iterate of each word\n",
    "for word in words:\n",
    "    \n",
    "    # Add stop and start tokens\n",
    "    chst = ['<S>'] + [char for char in word] + ['<E>']\n",
    "    # print(type(chst))\n",
    "    \n",
    "    # This will include up to ending token in right index\n",
    "    for tuplet in zip(chst, chst[1:]):\n",
    "        # Store running counts of each token\n",
    "        if tuplet in token_counts:\n",
    "            token_counts[tuplet] += 1\n",
    "        else: \n",
    "            token_counts[tuplet] = 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<S>', 'e') [1, 6]\n",
      "('e', 'm') [6, 14]\n",
      "('m', 'm') [14, 14]\n",
      "('m', 'a') [14, 2]\n",
      "('a', '<E>') [2, 0]\n",
      "('<S>', 'o') [1, 16]\n",
      "('o', 'l') [16, 13]\n",
      "('l', 'i') [13, 10]\n",
      "('i', 'v') [10, 23]\n",
      "('v', 'i') [23, 10]\n",
      "('i', 'a') [10, 2]\n",
      "('<S>', 'a') [1, 2]\n",
      "('a', 'v') [2, 23]\n",
      "('v', 'a') [23, 2]\n",
      "('<S>', 'i') [1, 10]\n",
      "('i', 's') [10, 20]\n",
      "('s', 'a') [20, 2]\n",
      "('a', 'b') [2, 3]\n",
      "('b', 'e') [3, 6]\n",
      "('e', 'l') [6, 13]\n",
      "('l', 'l') [13, 13]\n",
      "('l', 'a') [13, 2]\n",
      "('<S>', 's') [1, 20]\n",
      "('s', 'o') [20, 16]\n",
      "('o', 'p') [16, 17]\n",
      "('p', 'h') [17, 9]\n",
      "('h', 'i') [9, 10]\n",
      "('<S>', 'c') [1, 4]\n",
      "('c', 'h') [4, 9]\n",
      "('h', 'a') [9, 2]\n",
      "('a', 'r') [2, 19]\n",
      "('r', 'l') [19, 13]\n",
      "('l', 'o') [13, 16]\n",
      "('o', 't') [16, 21]\n",
      "('t', 't') [21, 21]\n",
      "('t', 'e') [21, 6]\n",
      "('e', '<E>') [6, 0]\n",
      "('<S>', 'm') [1, 14]\n",
      "('m', 'i') [14, 10]\n",
      "('a', 'm') [2, 14]\n",
      "('m', 'e') [14, 6]\n",
      "('<S>', 'h') [1, 9]\n",
      "('r', 'p') [19, 17]\n",
      "('p', 'e') [17, 6]\n",
      "('e', 'r') [6, 19]\n",
      "('r', '<E>') [19, 0]\n",
      "('e', 'v') [6, 23]\n",
      "('v', 'e') [23, 6]\n",
      "('l', 'y') [13, 26]\n",
      "('y', 'n') [26, 15]\n",
      "('n', '<E>') [15, 0]\n",
      "('b', 'i') [3, 10]\n",
      "('i', 'g') [10, 8]\n",
      "('g', 'a') [8, 2]\n",
      "('a', 'i') [2, 10]\n",
      "('i', 'l') [10, 13]\n",
      "('l', '<E>') [13, 0]\n",
      "('y', '<E>') [26, 0]\n",
      "('i', 'z') [10, 27]\n",
      "('z', 'a') [27, 2]\n",
      "('e', 't') [6, 21]\n",
      "('t', 'h') [21, 9]\n",
      "('h', '<E>') [9, 0]\n",
      "('r', 'y') [19, 26]\n",
      "('o', 'f') [16, 7]\n",
      "('f', 'i') [7, 10]\n",
      "('c', 'a') [4, 2]\n",
      "('r', 'i') [19, 10]\n",
      "('s', 'c') [20, 4]\n",
      "('l', 'e') [13, 6]\n",
      "('t', '<E>') [21, 0]\n",
      "('<S>', 'v') [1, 23]\n",
      "('i', 'c') [10, 4]\n",
      "('c', 't') [4, 21]\n",
      "('t', 'o') [21, 16]\n",
      "('o', 'r') [16, 19]\n",
      "('a', 'd') [2, 5]\n",
      "('d', 'i') [5, 10]\n",
      "('o', 'n') [16, 15]\n",
      "('<S>', 'l') [1, 13]\n",
      "('l', 'u') [13, 22]\n",
      "('u', 'n') [22, 15]\n",
      "('n', 'a') [15, 2]\n",
      "('<S>', 'g') [1, 8]\n",
      "('g', 'r') [8, 19]\n",
      "('r', 'a') [19, 2]\n",
      "('a', 'c') [2, 4]\n",
      "('c', 'e') [4, 6]\n",
      "('h', 'l') [9, 13]\n",
      "('o', 'e') [16, 6]\n",
      "('<S>', 'p') [1, 17]\n",
      "('e', 'n') [6, 15]\n",
      "('n', 'e') [15, 6]\n",
      "('a', 'y') [2, 26]\n",
      "('y', 'l') [26, 13]\n",
      "('<S>', 'r') [1, 19]\n",
      "('e', 'y') [6, 26]\n",
      "('<S>', 'z') [1, 27]\n",
      "('z', 'o') [27, 16]\n",
      "('<S>', 'n') [1, 15]\n",
      "('n', 'o') [15, 16]\n",
      "('e', 'a') [6, 2]\n",
      "('a', 'n') [2, 15]\n",
      "('n', 'n') [15, 15]\n",
      "('a', 'h') [2, 9]\n",
      "('d', 'd') [5, 5]\n",
      "('a', 'u') [2, 22]\n",
      "('u', 'b') [22, 3]\n",
      "('b', 'r') [3, 19]\n",
      "('r', 'e') [19, 6]\n",
      "('i', 'e') [10, 6]\n",
      "('s', 't') [20, 21]\n",
      "('a', 't') [2, 21]\n",
      "('t', 'a') [21, 2]\n",
      "('a', 'l') [2, 13]\n",
      "('a', 'z') [2, 27]\n",
      "('z', 'e') [27, 6]\n",
      "('i', 'o') [10, 16]\n",
      "('u', 'r') [22, 19]\n",
      "('r', 'o') [19, 16]\n",
      "('u', 'd') [22, 5]\n",
      "('d', 'r') [5, 19]\n",
      "('<S>', 'b') [1, 3]\n",
      "('o', 'o') [16, 16]\n",
      "('o', 'k') [16, 12]\n",
      "('k', 'l') [12, 13]\n",
      "('c', 'l') [4, 13]\n",
      "('i', 'r') [10, 19]\n",
      "('s', 'k') [20, 12]\n",
      "('k', 'y') [12, 26]\n",
      "('u', 'c') [22, 4]\n",
      "('c', 'y') [4, 26]\n",
      "('p', 'a') [17, 2]\n",
      "('s', 'l') [20, 13]\n",
      "('i', 'n') [10, 15]\n",
      "('o', 'v') [16, 23]\n",
      "('g', 'e') [8, 6]\n",
      "('e', 's') [6, 20]\n",
      "('s', 'i') [20, 10]\n",
      "('s', '<E>') [20, 0]\n",
      "('<S>', 'k') [1, 12]\n",
      "('k', 'e') [12, 6]\n",
      "('e', 'd') [6, 5]\n",
      "('d', 'y') [5, 26]\n",
      "('n', 't') [15, 21]\n",
      "('y', 'a') [26, 2]\n",
      "('<S>', 'w') [1, 24]\n",
      "('w', 'i') [24, 10]\n",
      "('o', 'w') [16, 24]\n",
      "('w', '<E>') [24, 0]\n",
      "('k', 'i') [12, 10]\n",
      "('n', 's') [15, 20]\n",
      "('a', 'o') [2, 16]\n",
      "('o', 'm') [16, 14]\n",
      "('i', '<E>') [10, 0]\n",
      "('a', 'a') [2, 2]\n",
      "('i', 'y') [10, 26]\n",
      "('d', 'e') [5, 6]\n",
      "('c', 'o') [4, 16]\n",
      "('r', 'u') [19, 22]\n",
      "('b', 'y') [3, 26]\n",
      "('s', 'e') [20, 6]\n",
      "('n', 'i') [15, 10]\n",
      "('i', 't') [10, 21]\n",
      "('t', 'y') [21, 26]\n",
      "('u', 't') [22, 21]\n",
      "('t', 'u') [21, 22]\n",
      "('u', 'm') [22, 14]\n",
      "('m', 'n') [14, 15]\n",
      "('g', 'i') [8, 10]\n",
      "('t', 'i') [21, 10]\n",
      "('<S>', 'q') [1, 18]\n",
      "('q', 'u') [18, 22]\n",
      "('u', 'i') [22, 10]\n",
      "('a', 'e') [2, 6]\n",
      "('e', 'h') [6, 9]\n",
      "('v', 'y') [23, 26]\n",
      "('p', 'i') [17, 10]\n",
      "('i', 'p') [10, 17]\n",
      "('y', 'd') [26, 5]\n",
      "('e', 'x') [6, 25]\n",
      "('x', 'a') [25, 2]\n",
      "('<S>', 'j') [1, 11]\n",
      "('j', 'o') [11, 16]\n",
      "('o', 's') [16, 20]\n",
      "('e', 'p') [6, 17]\n",
      "('j', 'u') [11, 22]\n",
      "('u', 'l') [22, 13]\n",
      "('<S>', 'd') [1, 5]\n",
      "('k', 'a') [12, 2]\n",
      "('e', 'e') [6, 6]\n",
      "('y', 't') [26, 21]\n",
      "('d', 'l') [5, 13]\n",
      "('c', 'k') [4, 12]\n",
      "('n', 'z') [15, 27]\n",
      "('z', 'i') [27, 10]\n",
      "('a', 'g') [2, 8]\n",
      "('d', 'a') [5, 2]\n",
      "('j', 'a') [11, 2]\n",
      "('h', 'e') [9, 6]\n",
      "('<S>', 'x') [1, 25]\n",
      "('x', 'i') [25, 10]\n",
      "('i', 'm') [10, 14]\n",
      "('e', 'i') [6, 10]\n",
      "('<S>', 't') [1, 21]\n",
      "('<S>', 'f') [1, 7]\n",
      "('f', 'a') [7, 2]\n",
      "('n', 'd') [15, 5]\n",
      "('r', 'g') [19, 8]\n",
      "('a', 's') [2, 20]\n",
      "('s', 'h') [20, 9]\n",
      "('b', 'a') [3, 2]\n",
      "('k', 'h') [12, 9]\n",
      "('s', 'm') [20, 14]\n",
      "('o', 'd') [16, 5]\n",
      "('r', 's') [19, 20]\n",
      "('g', 'h') [8, 9]\n",
      "('s', 'y') [20, 26]\n",
      "('y', 's') [26, 20]\n",
      "('s', 's') [20, 20]\n",
      "('e', 'c') [6, 4]\n",
      "('c', 'i') [4, 10]\n",
      "('m', 'o') [14, 16]\n",
      "('r', 'k') [19, 12]\n",
      "('n', 'l') [15, 13]\n",
      "('d', 'n') [5, 15]\n",
      "('r', 'd') [19, 5]\n",
      "('o', 'i') [16, 10]\n",
      "('t', 'r') [21, 19]\n",
      "('m', 'b') [14, 3]\n",
      "('r', 'm') [19, 14]\n",
      "('n', 'y') [15, 26]\n",
      "('d', 'o') [5, 16]\n",
      "('o', 'a') [16, 2]\n",
      "('o', 'c') [16, 4]\n",
      "('m', 'y') [14, 26]\n",
      "('s', 'u') [20, 22]\n",
      "('m', 'c') [14, 4]\n",
      "('p', 'r') [17, 19]\n",
      "('o', 'u') [16, 22]\n",
      "('r', 'n') [19, 15]\n",
      "('w', 'a') [24, 2]\n",
      "('e', 'b') [6, 3]\n",
      "('c', 'c') [4, 4]\n",
      "('a', 'w') [2, 24]\n",
      "('w', 'y') [24, 26]\n",
      "('y', 'e') [26, 6]\n",
      "('e', 'o') [6, 16]\n",
      "('a', 'k') [2, 12]\n",
      "('n', 'g') [15, 8]\n",
      "('k', 'o') [12, 16]\n",
      "('b', 'l') [3, 13]\n",
      "('h', 'o') [9, 16]\n",
      "('e', 'g') [6, 8]\n",
      "('f', 'r') [7, 19]\n",
      "('s', 'p') [20, 17]\n",
      "('l', 's') [13, 20]\n",
      "('y', 'z') [26, 27]\n",
      "('g', 'g') [8, 8]\n",
      "('z', 'u') [27, 22]\n",
      "('i', 'd') [10, 5]\n",
      "('m', '<E>') [14, 0]\n",
      "('o', 'g') [16, 8]\n",
      "('j', 'e') [11, 6]\n",
      "('g', 'n') [8, 15]\n",
      "('y', 'r') [26, 19]\n",
      "('c', '<E>') [4, 0]\n",
      "('c', 'q') [4, 18]\n",
      "('u', 'e') [22, 6]\n",
      "('i', 'f') [10, 7]\n",
      "('f', 'e') [7, 6]\n",
      "('i', 'x') [10, 25]\n",
      "('x', '<E>') [25, 0]\n",
      "('o', 'y') [16, 26]\n",
      "('g', 'o') [8, 16]\n",
      "('g', 't') [8, 21]\n",
      "('l', 't') [13, 21]\n",
      "('g', 'w') [8, 24]\n",
      "('w', 'e') [24, 6]\n",
      "('l', 'd') [13, 5]\n",
      "('a', 'p') [2, 17]\n",
      "('h', 'n') [9, 15]\n",
      "('t', 'l') [21, 13]\n",
      "('m', 'r') [14, 19]\n",
      "('n', 'c') [15, 4]\n",
      "('l', 'b') [13, 3]\n",
      "('i', 'k') [10, 12]\n",
      "('<S>', 'y') [1, 26]\n",
      "('t', 'z') [21, 27]\n",
      "('h', 'r') [9, 19]\n",
      "('j', 'i') [11, 10]\n",
      "('h', 't') [9, 21]\n",
      "('r', 'r') [19, 19]\n",
      "('z', 'l') [27, 13]\n",
      "('w', 'r') [24, 19]\n",
      "('b', 'b') [3, 3]\n",
      "('r', 't') [19, 21]\n",
      "('l', 'v') [13, 23]\n",
      "('e', 'j') [6, 11]\n",
      "('o', 'h') [16, 9]\n",
      "('u', 's') [22, 20]\n",
      "('i', 'b') [10, 3]\n",
      "('g', 'l') [8, 13]\n",
      "('h', 'y') [9, 26]\n",
      "('p', 'o') [17, 16]\n",
      "('p', 'p') [17, 17]\n",
      "('p', 'y') [17, 26]\n",
      "('n', 'r') [15, 19]\n",
      "('z', 'm') [27, 14]\n",
      "('v', 'o') [23, 16]\n",
      "('l', 'm') [13, 14]\n",
      "('o', 'x') [16, 25]\n",
      "('d', '<E>') [5, 0]\n",
      "('i', 'u') [10, 22]\n",
      "('v', '<E>') [23, 0]\n",
      "('f', 'f') [7, 7]\n",
      "('b', 'o') [3, 16]\n",
      "('e', 'k') [6, 12]\n",
      "('c', 'r') [4, 19]\n",
      "('d', 'g') [5, 8]\n",
      "('r', 'c') [19, 4]\n",
      "('r', 'h') [19, 9]\n",
      "('n', 'k') [15, 12]\n",
      "('h', 'u') [9, 22]\n",
      "('d', 's') [5, 20]\n",
      "('a', 'x') [2, 25]\n",
      "('y', 'c') [26, 4]\n",
      "('e', 'w') [6, 24]\n",
      "('v', 'k') [23, 12]\n",
      "('z', 'h') [27, 9]\n",
      "('w', 'h') [24, 9]\n",
      "('t', 'n') [21, 15]\n",
      "('x', 'l') [25, 13]\n",
      "('g', 'u') [8, 22]\n",
      "('u', 'a') [22, 2]\n",
      "('u', 'p') [22, 17]\n",
      "('u', 'g') [22, 8]\n",
      "('d', 'u') [5, 22]\n",
      "('l', 'c') [13, 4]\n",
      "('r', 'b') [19, 3]\n",
      "('a', 'q') [2, 18]\n",
      "('b', '<E>') [3, 0]\n",
      "('g', 'y') [8, 26]\n",
      "('y', 'p') [26, 17]\n",
      "('p', 't') [17, 21]\n",
      "('e', 'z') [6, 27]\n",
      "('z', 'r') [27, 19]\n",
      "('f', 'l') [7, 13]\n",
      "('o', '<E>') [16, 0]\n",
      "('o', 'b') [16, 3]\n",
      "('u', 'z') [22, 27]\n",
      "('z', '<E>') [27, 0]\n",
      "('i', 'q') [10, 18]\n",
      "('y', 'v') [26, 23]\n",
      "('n', 'v') [15, 23]\n",
      "('d', 'h') [5, 9]\n",
      "('g', 'd') [8, 5]\n",
      "('t', 's') [21, 20]\n",
      "('n', 'h') [15, 9]\n",
      "('y', 'j') [26, 11]\n",
      "('k', 'r') [12, 19]\n",
      "('z', 'b') [27, 3]\n",
      "('g', '<E>') [8, 0]\n",
      "('a', 'j') [2, 11]\n",
      "('r', 'j') [19, 11]\n",
      "('m', 'p') [14, 17]\n",
      "('p', 'b') [17, 3]\n",
      "('y', 'o') [26, 16]\n",
      "('z', 'y') [27, 26]\n",
      "('p', 'l') [17, 13]\n",
      "('l', 'k') [13, 12]\n",
      "('i', 'j') [10, 11]\n",
      "('x', 'e') [25, 6]\n",
      "('y', 'u') [26, 22]\n",
      "('l', 'n') [13, 15]\n",
      "('u', 'x') [22, 25]\n",
      "('i', 'h') [10, 9]\n",
      "('w', 's') [24, 20]\n",
      "('k', 's') [12, 20]\n",
      "('m', 'u') [14, 22]\n",
      "('y', 'k') [26, 12]\n",
      "('e', 'f') [6, 7]\n",
      "('k', '<E>') [12, 0]\n",
      "('y', 'm') [26, 14]\n",
      "('z', 'z') [27, 27]\n",
      "('m', 'd') [14, 5]\n",
      "('s', 'r') [20, 19]\n",
      "('e', 'u') [6, 22]\n",
      "('l', 'h') [13, 9]\n",
      "('a', 'f') [2, 7]\n",
      "('r', 'w') [19, 24]\n",
      "('n', 'u') [15, 22]\n",
      "('v', 'r') [23, 19]\n",
      "('m', 's') [14, 20]\n",
      "('<S>', 'u') [1, 22]\n",
      "('f', 's') [7, 20]\n",
      "('y', 'b') [26, 3]\n",
      "('x', 'o') [25, 16]\n",
      "('g', 's') [8, 20]\n",
      "('x', 'y') [25, 26]\n",
      "('w', 'n') [24, 15]\n",
      "('j', 'h') [11, 9]\n",
      "('f', 'n') [7, 15]\n",
      "('n', 'j') [15, 11]\n",
      "('r', 'v') [19, 23]\n",
      "('n', 'm') [15, 14]\n",
      "('t', 'c') [21, 4]\n",
      "('s', 'w') [20, 24]\n",
      "('k', 't') [12, 21]\n",
      "('f', 't') [7, 21]\n",
      "('x', 't') [25, 21]\n",
      "('u', 'v') [22, 23]\n",
      "('k', 'k') [12, 12]\n",
      "('s', 'n') [20, 15]\n",
      "('u', '<E>') [22, 0]\n",
      "('j', 'r') [11, 19]\n",
      "('y', 'x') [26, 25]\n",
      "('h', 'm') [9, 14]\n",
      "('e', 'q') [6, 18]\n",
      "('u', 'o') [22, 16]\n",
      "('f', '<E>') [7, 0]\n",
      "('h', 'z') [9, 27]\n",
      "('h', 'k') [9, 12]\n",
      "('y', 'g') [26, 8]\n",
      "('q', 'r') [18, 19]\n",
      "('v', 'n') [23, 15]\n",
      "('s', 'd') [20, 5]\n",
      "('y', 'i') [26, 10]\n",
      "('n', 'w') [15, 24]\n",
      "('d', 'v') [5, 23]\n",
      "('h', 'v') [9, 23]\n",
      "('x', 'w') [25, 24]\n",
      "('o', 'z') [16, 27]\n",
      "('k', 'u') [12, 22]\n",
      "('u', 'h') [22, 9]\n",
      "('k', 'n') [12, 15]\n",
      "('s', 'b') [20, 3]\n",
      "('i', 'i') [10, 10]\n",
      "('y', 'y') [26, 26]\n",
      "('r', 'z') [19, 27]\n",
      "('l', 'g') [13, 8]\n",
      "('l', 'p') [13, 17]\n",
      "('p', '<E>') [17, 0]\n",
      "('b', 'u') [3, 22]\n",
      "('f', 'u') [7, 22]\n",
      "('b', 'h') [3, 9]\n",
      "('f', 'y') [7, 26]\n",
      "('u', 'w') [22, 24]\n",
      "('x', 'u') [25, 22]\n",
      "('q', '<E>') [18, 0]\n",
      "('l', 'r') [13, 19]\n",
      "('m', 'h') [14, 9]\n",
      "('l', 'w') [13, 24]\n",
      "('j', '<E>') [11, 0]\n",
      "('s', 'v') [20, 23]\n",
      "('m', 'l') [14, 13]\n",
      "('n', 'f') [15, 7]\n",
      "('u', 'j') [22, 11]\n",
      "('f', 'o') [7, 16]\n",
      "('j', 'l') [11, 13]\n",
      "('t', 'g') [21, 8]\n",
      "('j', 'm') [11, 14]\n",
      "('v', 'v') [23, 23]\n",
      "('p', 's') [17, 20]\n",
      "('t', 'w') [21, 24]\n",
      "('x', 'c') [25, 4]\n",
      "('u', 'k') [22, 12]\n",
      "('v', 'l') [23, 13]\n",
      "('h', 'd') [9, 5]\n",
      "('l', 'z') [13, 27]\n",
      "('k', 'w') [12, 24]\n",
      "('n', 'b') [15, 3]\n",
      "('q', 's') [18, 20]\n",
      "('i', 'w') [10, 24]\n",
      "('c', 's') [4, 20]\n",
      "('h', 's') [9, 20]\n",
      "('m', 't') [14, 21]\n",
      "('h', 'w') [9, 24]\n",
      "('x', 'x') [25, 25]\n",
      "('t', 'x') [21, 25]\n",
      "('d', 'z') [5, 27]\n",
      "('x', 'z') [25, 27]\n",
      "('t', 'm') [21, 14]\n",
      "('t', 'j') [21, 11]\n",
      "('u', 'q') [22, 18]\n",
      "('q', 'a') [18, 2]\n",
      "('f', 'k') [7, 12]\n",
      "('z', 'n') [27, 15]\n",
      "('l', 'j') [13, 11]\n",
      "('j', 'w') [11, 24]\n",
      "('v', 'u') [23, 22]\n",
      "('c', 'j') [4, 11]\n",
      "('h', 'b') [9, 3]\n",
      "('z', 't') [27, 21]\n",
      "('p', 'u') [17, 22]\n",
      "('m', 'z') [14, 27]\n",
      "('x', 's') [25, 20]\n",
      "('b', 't') [3, 21]\n",
      "('u', 'y') [22, 26]\n",
      "('d', 'j') [5, 11]\n",
      "('j', 's') [11, 20]\n",
      "('w', 'u') [24, 22]\n",
      "('o', 'j') [16, 11]\n",
      "('b', 's') [3, 20]\n",
      "('d', 'w') [5, 24]\n",
      "('w', 'o') [24, 16]\n",
      "('j', 'n') [11, 15]\n",
      "('w', 't') [24, 21]\n",
      "('l', 'f') [13, 7]\n",
      "('d', 'm') [5, 14]\n",
      "('p', 'j') [17, 11]\n",
      "('j', 'y') [11, 26]\n",
      "('y', 'f') [26, 7]\n",
      "('q', 'i') [18, 10]\n",
      "('j', 'v') [11, 23]\n",
      "('q', 'l') [18, 13]\n",
      "('s', 'z') [20, 27]\n",
      "('k', 'm') [12, 14]\n",
      "('w', 'l') [24, 13]\n",
      "('p', 'f') [17, 7]\n",
      "('q', 'w') [18, 24]\n",
      "('n', 'x') [15, 25]\n",
      "('k', 'c') [12, 4]\n",
      "('t', 'v') [21, 23]\n",
      "('c', 'u') [4, 22]\n",
      "('z', 'k') [27, 12]\n",
      "('c', 'z') [4, 27]\n",
      "('y', 'q') [26, 18]\n",
      "('y', 'h') [26, 9]\n",
      "('r', 'f') [19, 7]\n",
      "('s', 'j') [20, 11]\n",
      "('h', 'j') [9, 11]\n",
      "('g', 'b') [8, 3]\n",
      "('u', 'f') [22, 7]\n",
      "('s', 'f') [20, 7]\n",
      "('q', 'e') [18, 6]\n",
      "('b', 'c') [3, 4]\n",
      "('c', 'd') [4, 5]\n",
      "('z', 'j') [27, 11]\n",
      "('n', 'q') [15, 18]\n",
      "('m', 'f') [14, 7]\n",
      "('p', 'n') [17, 15]\n",
      "('f', 'z') [7, 27]\n",
      "('b', 'n') [3, 15]\n",
      "('w', 'd') [24, 5]\n",
      "('w', 'b') [24, 3]\n",
      "('b', 'd') [3, 5]\n",
      "('z', 's') [27, 20]\n",
      "('p', 'c') [17, 4]\n",
      "('h', 'g') [9, 8]\n",
      "('m', 'j') [14, 11]\n",
      "('w', 'w') [24, 24]\n",
      "('k', 'j') [12, 11]\n",
      "('h', 'p') [9, 17]\n",
      "('j', 'k') [11, 12]\n",
      "('o', 'q') [16, 18]\n",
      "('f', 'w') [7, 24]\n",
      "('f', 'h') [7, 9]\n",
      "('w', 'm') [24, 14]\n",
      "('b', 'j') [3, 11]\n",
      "('r', 'q') [19, 18]\n",
      "('z', 'c') [27, 4]\n",
      "('z', 'v') [27, 23]\n",
      "('f', 'g') [7, 8]\n",
      "('n', 'p') [15, 17]\n",
      "('z', 'g') [27, 8]\n",
      "('d', 't') [5, 21]\n",
      "('w', 'f') [24, 7]\n",
      "('d', 'f') [5, 7]\n",
      "('w', 'k') [24, 12]\n",
      "('q', 'm') [18, 14]\n",
      "('k', 'z') [12, 27]\n",
      "('j', 'j') [11, 11]\n",
      "('c', 'p') [4, 17]\n",
      "('p', 'k') [17, 12]\n",
      "('p', 'm') [17, 14]\n",
      "('j', 'd') [11, 5]\n",
      "('r', 'x') [19, 25]\n",
      "('x', 'n') [25, 15]\n",
      "('d', 'c') [5, 4]\n",
      "('g', 'j') [8, 11]\n",
      "('x', 'f') [25, 7]\n",
      "('j', 'c') [11, 4]\n",
      "('s', 'q') [20, 18]\n",
      "('k', 'f') [12, 7]\n",
      "('z', 'p') [27, 17]\n",
      "('j', 't') [11, 21]\n",
      "('k', 'b') [12, 3]\n",
      "('m', 'k') [14, 12]\n",
      "('m', 'w') [14, 24]\n",
      "('x', 'h') [25, 9]\n",
      "('h', 'f') [9, 7]\n",
      "('x', 'd') [25, 5]\n",
      "('y', 'w') [26, 24]\n",
      "('z', 'w') [27, 24]\n",
      "('d', 'k') [5, 12]\n",
      "('c', 'g') [4, 8]\n",
      "('u', 'u') [22, 22]\n",
      "('t', 'f') [21, 7]\n",
      "('g', 'm') [8, 14]\n",
      "('m', 'v') [14, 23]\n",
      "('c', 'x') [4, 25]\n",
      "('h', 'c') [9, 4]\n",
      "('g', 'f') [8, 7]\n",
      "('q', 'o') [18, 16]\n",
      "('l', 'q') [13, 18]\n",
      "('v', 'b') [23, 3]\n",
      "('j', 'p') [11, 17]\n",
      "('k', 'd') [12, 5]\n",
      "('g', 'z') [8, 27]\n",
      "('v', 'd') [23, 5]\n",
      "('d', 'b') [5, 3]\n",
      "('v', 'h') [23, 9]\n",
      "('k', 'v') [12, 23]\n",
      "('h', 'h') [9, 9]\n",
      "('s', 'g') [20, 8]\n",
      "('g', 'v') [8, 23]\n",
      "('d', 'q') [5, 18]\n",
      "('x', 'b') [25, 3]\n",
      "('w', 'z') [24, 27]\n",
      "('h', 'q') [9, 18]\n",
      "('j', 'b') [11, 3]\n",
      "('z', 'd') [27, 5]\n",
      "('x', 'm') [25, 14]\n",
      "('w', 'g') [24, 8]\n",
      "('t', 'b') [21, 3]\n",
      "('z', 'x') [27, 25]\n"
     ]
    }
   ],
   "source": [
    "# Create 2D tensor to store frequency of bigram pairs. \n",
    "data = torch.zeros((len(alphabet), len(alphabet)), dtype=torch.int32)\n",
    "\n",
    "\n",
    "char_to_int\n",
    "# # Iterate over tuplets\n",
    "for tuplet in token_counts.items():\n",
    "    # store characters pairs and freq\n",
    "    chpairs, freq = tuplet\n",
    "    # Assign index of data according to character values\n",
    "    data_index = [char_to_int[char] for char in chpairs]\n",
    "    print(chpairs, data_index)\n",
    "    data[data_index[0]][data_index[1]] = freq\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert data tensor to numpy array\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_np \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create heatmap using Seaborn with annotations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m15\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Convert data tensor to numpy array\n",
    "data_np = data.numpy()\n",
    "\n",
    "# Create heatmap using Seaborn with annotations\n",
    "plt.figure(figsize=(20, 15), dpi=200)\n",
    "sns.heatmap(data_np, cmap='YlGnBu', annot=True, fmt='.0f', linewidths=.5)\n",
    "\n",
    "# Set custom tick labels for x-axis (Second Character)\n",
    "plt.xticks(np.arange(len(alphabet)) + 0.5, [int_to_char[i] for i in range(len(alphabet))])\n",
    "# Set custom tick labels for y-axis (First Character)\n",
    "plt.yticks(np.arange(len(alphabet)) + 0.5, [int_to_char[i] for i in range(len(alphabet))])\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Bigram Frequency Heatmap')\n",
    "plt.xlabel('Second Character')\n",
    "plt.ylabel('First Character')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02,\n",
      "         3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02,\n",
      "         3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02,\n",
      "         3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02,\n",
      "         3.5714e-02, 3.5714e-02, 3.5714e-02, 3.5714e-02],\n",
      "        [3.1218e-15, 3.1218e-15, 1.3767e-01, 4.0770e-02, 4.8138e-02, 5.2758e-02,\n",
      "         4.7794e-02, 1.3018e-02, 2.0885e-02, 2.7284e-02, 1.8450e-02, 7.5610e-02,\n",
      "         9.2498e-02, 4.9074e-02, 7.9231e-02, 3.5776e-02, 1.2300e-02, 1.6077e-02,\n",
      "         2.8720e-03, 5.1166e-02, 6.4153e-02, 4.0833e-02, 2.4350e-03, 1.1738e-02,\n",
      "         9.5839e-03, 4.1832e-03, 1.6702e-02, 2.9001e-02],\n",
      "        [1.9596e-01, 2.9512e-15, 1.6408e-02, 1.5966e-02, 1.3870e-02, 3.0751e-02,\n",
      "         2.0422e-02, 3.9546e-03, 4.9579e-03, 6.8821e-02, 4.8694e-02, 5.1645e-03,\n",
      "         1.6763e-02, 7.4605e-02, 4.8222e-02, 1.6048e-01, 1.8592e-03, 2.4199e-03,\n",
      "         1.7707e-03, 9.6326e-02, 3.2994e-02, 2.0274e-02, 1.1244e-02, 2.4613e-02,\n",
      "         4.7514e-03, 5.3711e-03, 6.0499e-02, 1.2838e-02],\n",
      "        [4.3100e-02, 3.7807e-14, 1.2136e-01, 1.4367e-02, 3.7807e-04, 2.4575e-02,\n",
      "         2.4764e-01, 3.7807e-14, 3.7807e-14, 1.5501e-02, 8.2042e-02, 3.7807e-04,\n",
      "         3.7807e-14, 3.8941e-02, 3.7807e-14, 1.5123e-03, 3.9698e-02, 3.7807e-14,\n",
      "         3.7807e-14, 3.1834e-01, 3.0246e-03, 7.5614e-04, 1.7013e-02, 3.7807e-14,\n",
      "         3.7807e-14, 3.7807e-14, 3.1380e-02, 3.7807e-14],\n",
      "        [2.7463e-02, 2.8313e-14, 2.3075e-01, 2.8313e-14, 1.1891e-02, 2.8313e-04,\n",
      "         1.5600e-01, 2.8313e-14, 5.6625e-04, 1.8800e-01, 7.6727e-02, 8.4938e-04,\n",
      "         8.9468e-02, 3.2843e-02, 2.8313e-14, 2.8313e-14, 1.0759e-01, 2.8313e-04,\n",
      "         3.1144e-03, 2.1518e-02, 1.4156e-03, 9.9094e-03, 9.9094e-03, 2.8313e-14,\n",
      "         2.8313e-14, 8.4938e-04, 2.9445e-02, 1.1325e-03],\n",
      "        [9.3886e-02, 1.8195e-14, 2.3708e-01, 1.8195e-04, 5.4585e-04, 2.7111e-02,\n",
      "         2.3344e-01, 9.0975e-04, 4.5488e-03, 2.1470e-02, 1.2263e-01, 1.6376e-03,\n",
      "         5.4585e-04, 1.0917e-02, 5.4585e-03, 5.6405e-03, 6.8777e-02, 1.8195e-14,\n",
      "         1.8195e-04, 7.7147e-02, 5.2766e-03, 7.2780e-04, 1.6739e-02, 3.0932e-03,\n",
      "         4.1849e-03, 1.8195e-14, 5.7678e-02, 1.8195e-04],\n",
      "        [1.9503e-01, 4.8964e-15, 3.3247e-02, 5.9247e-03, 7.4916e-03, 1.8802e-02,\n",
      "         6.2234e-02, 4.0151e-03, 6.1206e-03, 7.4426e-03, 4.0053e-02, 2.6930e-03,\n",
      "         8.7157e-03, 1.5904e-01, 3.7654e-02, 1.3098e-01, 1.3171e-02, 4.0640e-03,\n",
      "         6.8550e-04, 9.5872e-02, 4.2158e-02, 2.8399e-02, 3.3785e-03, 2.2671e-02,\n",
      "         2.4482e-03, 6.4633e-03, 5.2392e-02, 8.8626e-03],\n",
      "        [8.8398e-02, 1.1050e-13, 2.6740e-01, 1.1050e-13, 1.1050e-13, 1.1050e-13,\n",
      "         1.3591e-01, 4.8619e-02, 1.1050e-03, 1.1050e-03, 1.7680e-01, 1.1050e-13,\n",
      "         2.2099e-03, 2.2099e-02, 1.1050e-13, 4.4199e-03, 6.6298e-02, 1.1050e-13,\n",
      "         1.1050e-13, 1.2597e-01, 6.6298e-03, 1.9890e-02, 1.1050e-02, 1.1050e-13,\n",
      "         4.4199e-03, 1.1050e-13, 1.5470e-02, 2.2099e-03],\n",
      "        [5.6046e-02, 5.1894e-14, 1.7125e-01, 1.5568e-03, 5.1894e-14, 9.8599e-03,\n",
      "         1.7333e-01, 5.1894e-04, 1.2974e-02, 1.8682e-01, 9.8599e-02, 1.5568e-03,\n",
      "         5.1894e-14, 1.6606e-02, 3.1136e-03, 1.4011e-02, 4.3072e-02, 5.1894e-14,\n",
      "         5.1894e-14, 1.0431e-01, 1.5568e-02, 1.6087e-02, 4.4110e-02, 5.1894e-04,\n",
      "         1.3492e-02, 5.1894e-14, 1.6087e-02, 5.1894e-04],\n",
      "        [3.1631e-01, 1.3130e-14, 2.9464e-01, 1.0504e-03, 2.6261e-04, 3.1513e-03,\n",
      "         8.8498e-02, 2.6261e-04, 2.6261e-04, 1.3130e-04, 9.5720e-02, 1.1817e-03,\n",
      "         3.8078e-03, 2.4291e-02, 1.5362e-02, 1.8120e-02, 3.7684e-02, 1.3130e-04,\n",
      "         1.3130e-04, 2.6786e-02, 4.0704e-03, 9.3225e-03, 2.1796e-02, 5.1208e-03,\n",
      "         1.3130e-03, 1.3130e-14, 2.7967e-02, 2.6261e-03],\n",
      "        [1.4061e-01, 5.6494e-15, 1.3813e-01, 6.2143e-03, 2.8755e-02, 2.4857e-02,\n",
      "         9.3385e-02, 5.7059e-03, 2.4179e-02, 5.3669e-03, 4.6325e-03, 4.2935e-03,\n",
      "         2.5140e-02, 7.5984e-02, 2.4123e-02, 1.2011e-01, 3.3218e-02, 2.9942e-03,\n",
      "         2.9377e-03, 4.7963e-02, 7.4346e-02, 3.0563e-02, 6.1578e-03, 1.5197e-02,\n",
      "         4.5195e-04, 5.0280e-03, 4.4009e-02, 1.5649e-02],\n",
      "        [2.4483e-02, 3.4483e-14, 5.0793e-01, 3.4483e-04, 1.3793e-03, 1.3793e-03,\n",
      "         1.5172e-01, 3.4483e-14, 3.4483e-14, 1.5517e-02, 4.1034e-02, 6.8966e-04,\n",
      "         6.8966e-04, 3.1034e-03, 1.7241e-03, 6.8966e-04, 1.6517e-01, 3.4483e-04,\n",
      "         3.4483e-14, 3.7931e-03, 2.4138e-03, 6.8966e-04, 6.9655e-02, 1.7241e-03,\n",
      "         2.0690e-03, 3.4483e-14, 3.4483e-03, 3.4483e-14],\n",
      "        [7.2024e-02, 1.9841e-14, 3.4345e-01, 3.9683e-04, 3.9683e-04, 3.9683e-04,\n",
      "         1.7758e-01, 1.9841e-04, 1.9841e-14, 6.0913e-02, 1.0099e-01, 3.9683e-04,\n",
      "         3.9683e-03, 2.7579e-02, 1.7857e-03, 5.1587e-03, 6.8254e-02, 1.9841e-14,\n",
      "         1.9841e-14, 2.1627e-02, 1.8849e-02, 3.3730e-03, 9.9206e-03, 3.9683e-04,\n",
      "         6.7460e-03, 1.9841e-14, 7.5198e-02, 3.9683e-04],\n",
      "        [9.4140e-02, 7.1644e-15, 1.8792e-01, 3.7255e-03, 1.7911e-03, 9.8868e-03,\n",
      "         2.0927e-01, 1.5762e-03, 4.2986e-04, 1.3612e-03, 1.7768e-01, 4.2986e-04,\n",
      "         1.7194e-03, 9.6361e-02, 4.2986e-03, 1.0030e-03, 4.9577e-02, 1.0747e-03,\n",
      "         2.1493e-04, 1.2896e-03, 6.7345e-03, 5.5165e-03, 2.3212e-02, 5.1583e-03,\n",
      "         1.1463e-03, 7.1644e-15, 1.1377e-01, 7.1644e-04],\n",
      "        [7.7687e-02, 1.5056e-14, 3.8994e-01, 1.6862e-02, 7.6784e-03, 3.6134e-03,\n",
      "         1.2316e-01, 1.5056e-04, 1.5056e-14, 7.5279e-04, 1.8910e-01, 1.0539e-03,\n",
      "         1.5056e-04, 7.5279e-04, 2.5294e-02, 3.0111e-03, 6.8052e-02, 5.7212e-03,\n",
      "         1.5056e-14, 1.4604e-02, 5.2695e-03, 6.0223e-04, 2.0927e-02, 4.5167e-04,\n",
      "         3.0111e-04, 1.5056e-14, 4.3210e-02, 1.6561e-03],\n",
      "        [3.6902e-01, 5.4564e-15, 1.6244e-01, 4.3651e-04, 1.1622e-02, 3.8413e-02,\n",
      "         7.4153e-02, 6.0021e-04, 1.4896e-02, 1.4187e-03, 9.4123e-02, 2.4008e-03,\n",
      "         3.1647e-03, 1.0640e-02, 1.0367e-03, 1.0400e-01, 2.7064e-02, 2.7282e-04,\n",
      "         1.0913e-04, 2.4008e-03, 1.5169e-02, 2.4172e-02, 5.2382e-03, 3.0010e-03,\n",
      "         6.0021e-04, 3.2739e-04, 2.5372e-02, 7.9118e-03],\n",
      "        [1.0776e-01, 1.2604e-14, 1.8780e-02, 1.7646e-02, 1.4369e-02, 2.3948e-02,\n",
      "         1.6637e-02, 4.2854e-03, 5.5458e-03, 2.1553e-02, 8.6967e-03, 2.0166e-03,\n",
      "         8.5707e-03, 7.8019e-02, 3.2896e-02, 3.0388e-01, 1.4495e-02, 1.1974e-02,\n",
      "         3.7812e-04, 1.3348e-01, 6.3524e-02, 1.4873e-02, 3.4661e-02, 2.2183e-02,\n",
      "         1.4369e-02, 5.6718e-03, 1.2982e-02, 6.8062e-03],\n",
      "        [3.2164e-02, 9.7466e-14, 2.0370e-01, 1.9493e-03, 9.7466e-04, 9.7466e-14,\n",
      "         1.9201e-01, 9.7466e-04, 9.7466e-14, 1.9883e-01, 5.9454e-02, 9.7466e-04,\n",
      "         9.7466e-04, 1.5595e-02, 9.7466e-04, 9.7466e-04, 5.7505e-02, 3.8012e-02,\n",
      "         9.7466e-14, 1.4717e-01, 1.5595e-02, 1.6569e-02, 3.8986e-03, 9.7466e-14,\n",
      "         9.7466e-14, 9.7466e-14, 1.1696e-02, 9.7466e-14],\n",
      "        [1.0294e-01, 3.6765e-13, 4.7794e-02, 3.6765e-13, 3.6765e-13, 3.6765e-13,\n",
      "         3.6765e-03, 3.6765e-13, 3.6765e-13, 3.6765e-13, 4.7794e-02, 3.6765e-13,\n",
      "         3.6765e-13, 3.6765e-03, 7.3529e-03, 3.6765e-13, 7.3529e-03, 3.6765e-13,\n",
      "         3.6765e-13, 3.6765e-03, 7.3529e-03, 3.6765e-13, 7.5735e-01, 3.6765e-13,\n",
      "         1.1029e-02, 3.6765e-13, 3.6765e-13, 3.6765e-13],\n",
      "        [1.0843e-01, 7.8740e-15, 1.8551e-01, 3.2283e-03, 7.7953e-03, 1.4724e-02,\n",
      "         1.3362e-01, 7.0866e-04, 5.9843e-03, 9.5276e-03, 2.3882e-01, 1.9685e-03,\n",
      "         7.0866e-03, 3.2520e-02, 1.2756e-02, 1.1024e-02, 6.8425e-02, 1.1024e-03,\n",
      "         1.2598e-03, 3.3465e-02, 1.4961e-02, 1.6378e-02, 1.9843e-02, 6.2992e-03,\n",
      "         1.6535e-03, 2.3622e-04, 6.0866e-02, 1.8110e-03],\n",
      "        [1.4421e-01, 1.2337e-14, 1.4816e-01, 2.5907e-03, 7.4019e-03, 1.1103e-03,\n",
      "         1.0906e-01, 2.4673e-04, 2.4673e-04, 1.5852e-01, 8.4382e-02, 2.4673e-04,\n",
      "         1.0116e-02, 3.4419e-02, 1.1103e-02, 2.9608e-03, 6.5507e-02, 6.2916e-03,\n",
      "         1.2337e-04, 6.7851e-03, 5.6871e-02, 9.4375e-02, 2.2823e-02, 1.7271e-03,\n",
      "         2.9608e-03, 1.2337e-14, 2.6524e-02, 1.2337e-03],\n",
      "        [8.6715e-02, 1.7953e-14, 1.8438e-01, 1.7953e-04, 3.0521e-03, 1.7953e-14,\n",
      "         1.2855e-01, 3.5907e-04, 3.5907e-04, 1.1616e-01, 9.5512e-02, 5.3860e-04,\n",
      "         1.7953e-14, 2.4057e-02, 7.1813e-04, 3.9497e-03, 1.1975e-01, 1.7953e-14,\n",
      "         1.7953e-14, 6.3196e-02, 6.2837e-03, 6.7145e-02, 1.4004e-02, 2.6930e-03,\n",
      "         1.9749e-03, 3.5907e-04, 6.1221e-02, 1.8851e-02],\n",
      "        [4.9442e-02, 3.1898e-14, 5.1994e-02, 3.2855e-02, 3.2855e-02, 4.3381e-02,\n",
      "         5.3907e-02, 6.0606e-03, 1.4992e-02, 1.8501e-02, 3.8596e-02, 4.4657e-03,\n",
      "         2.9665e-02, 9.6013e-02, 4.9123e-02, 8.7719e-02, 3.1898e-03, 5.1037e-03,\n",
      "         3.1898e-03, 1.3206e-01, 1.5120e-01, 2.6156e-02, 9.5694e-04, 1.1802e-02,\n",
      "         2.7432e-02, 1.0845e-02, 4.1467e-03, 1.4354e-02],\n",
      "        [3.4201e-02, 3.8865e-14, 2.4951e-01, 3.8865e-04, 3.8865e-14, 3.8865e-04,\n",
      "         2.2075e-01, 3.8865e-14, 3.8865e-14, 3.8865e-04, 3.5406e-01, 3.8865e-14,\n",
      "         1.1660e-03, 5.4411e-03, 3.8865e-14, 3.1092e-03, 5.9464e-02, 3.8865e-14,\n",
      "         3.8865e-14, 1.8655e-02, 3.8865e-14, 3.8865e-14, 2.7206e-03, 2.7206e-03,\n",
      "         3.8865e-14, 3.8865e-14, 4.7027e-02, 3.8865e-14],\n",
      "        [5.4898e-02, 1.0764e-13, 3.0140e-01, 1.0764e-03, 1.0764e-13, 8.6114e-03,\n",
      "         1.6039e-01, 2.1529e-03, 1.0764e-03, 2.4758e-02, 1.5931e-01, 1.0764e-13,\n",
      "         6.4586e-03, 1.3994e-02, 2.1529e-03, 6.2433e-02, 3.8751e-02, 1.0764e-13,\n",
      "         1.0764e-13, 2.3681e-02, 2.1529e-02, 8.6114e-03, 2.6911e-02, 1.0764e-13,\n",
      "         2.1529e-03, 1.0764e-13, 7.8579e-02, 1.0764e-03],\n",
      "        [2.3529e-01, 1.4347e-13, 1.4778e-01, 1.4347e-03, 5.7389e-03, 7.1736e-03,\n",
      "         5.1650e-02, 4.3042e-03, 1.4347e-13, 1.4347e-03, 1.4634e-01, 1.4347e-13,\n",
      "         1.4347e-13, 5.5954e-02, 1.4347e-03, 1.4347e-03, 5.8824e-02, 1.4347e-13,\n",
      "         1.4347e-13, 1.4347e-13, 4.4476e-02, 1.0043e-01, 7.1736e-03, 1.4347e-13,\n",
      "         4.3042e-03, 5.4519e-02, 4.3042e-02, 2.7260e-02],\n",
      "        [2.0530e-01, 1.0229e-14, 2.1921e-01, 2.7619e-03, 1.1764e-02, 2.7823e-02,\n",
      "         3.0790e-02, 1.2275e-03, 3.0687e-03, 2.2504e-03, 1.9640e-02, 2.3527e-03,\n",
      "         8.7971e-03, 1.1293e-01, 1.5139e-02, 1.8678e-01, 2.7721e-02, 1.5344e-03,\n",
      "         6.1375e-04, 2.9767e-02, 4.1019e-02, 1.0638e-02, 1.4423e-02, 1.0843e-02,\n",
      "         4.0917e-04, 2.8642e-03, 2.3527e-03, 7.9787e-03],\n",
      "        [6.6722e-02, 4.1701e-14, 3.5863e-01, 1.6681e-03, 8.3403e-04, 8.3403e-04,\n",
      "         1.5555e-01, 4.1701e-14, 4.1701e-04, 1.7932e-02, 1.5179e-01, 8.3403e-04,\n",
      "         8.3403e-04, 5.1293e-02, 1.4595e-02, 1.6681e-03, 4.5872e-02, 8.3403e-04,\n",
      "         4.1701e-14, 1.3344e-02, 1.6681e-03, 1.6681e-03, 3.0442e-02, 8.3403e-04,\n",
      "         1.2510e-03, 4.1701e-04, 6.1301e-02, 1.8766e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Create a generator object\n",
    "generator = torch.Generator()\n",
    "\n",
    "# Define the value to fill\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Set seed using manual_seed method\n",
    "generator.manual_seed(42)\n",
    "\n",
    "# # Convert data to float for probabilities\n",
    "norm_data = (data + epsilon).to(torch.float32)\n",
    "\n",
    "# Normalize data according to valid pdf\n",
    "norm_data /= norm_data.sum(dim=1, keepdim=True)\n",
    "\n",
    "# # # Add very small number to clear null values\n",
    "# norm_data[0].fill_(epsilon)\n",
    "\n",
    "print(norm_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store list of sampled words\n",
    "sample_outcome = []\n",
    "\n",
    "for _ in range(10):\n",
    "    # Word initializes with start token \n",
    "    ix = 1\n",
    "    word = int_to_char[ix]\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # get random character given previous character \n",
    "        ix = torch.multinomial(norm_data[ix], num_samples=1, generator=generator).item()\n",
    "        \n",
    "        # store new character token\n",
    "        char = int_to_char[ix]\n",
    "        \n",
    "        # add sampled letter to word \n",
    "        word += char\n",
    "        \n",
    "        # check if terminating token has been reached\n",
    "        if char == '<E>':\n",
    "            # add word to list of sampled words\n",
    "            sample_outcome.append(word)\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = words[0]\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "# Add start and end character tokens\n",
    "training = ['<S>'] + [char for char in training] + ['<E>']\n",
    "\n",
    "# Iterate over bigrams \n",
    "for ch1, ch2 in zip(training, training[1:]):\n",
    "    # add prior\n",
    "    inputs.append(char_to_int[ch1])\n",
    "    # add target\n",
    "    targets.append(char_to_int[ch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_enc = F.one_hot(torch.tensor(inputs), num_classes=28)\n",
    "inputs_enc = inputs_enc.to(torch.float32)\n",
    "\n",
    "targets_enc = F.one_hot(torch.tensor(targets), num_classes=28)\n",
    "targets_enc = targets_enc.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.rand((28, 28), requires_grad=True)\n",
    "weights = weights.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5086, grad_fn=<NegBackward0>)\n",
      "tensor(3.3379, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate logits, unnormalized pre-probabilities\n",
    "logits = weights @ inputs_enc.T\n",
    "# print(logits)\n",
    "\n",
    "# Transpose for readability\n",
    "logits = logits.T\n",
    "\n",
    "# Convert each output to valid probability distribution, across cols\n",
    "# dim=0 / each row is a probability distribution over the alphabet given the prior / input token (char)\n",
    "probabilities = logits.exp() / logits.exp().sum(dim=1, keepdim=True)\n",
    "# print(probabilities) #compare to softmax\n",
    "\n",
    "# Apply softmax to output of linear layer\n",
    "softmax = F.softmax(logits, dim = 1)\n",
    "# print(softmax) #compare to probabilities\n",
    "\n",
    "# Calculate negative log likelihood = loss of data for practice (GLM)\n",
    "lik = softmax[torch.arange(5),targets]\n",
    "log_lik = lik.log().mean()\n",
    "neg_log_lik = -log_lik\n",
    "loss = neg_log_lik\n",
    "print(loss)\n",
    "\n",
    "# Compare calculated loss with cross entropy loss. \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion_result = criterion(softmax, targets_enc)\n",
    "print(criterion_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 14, 14, 2, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out prev gradients\n",
    "weights.grad = None\n",
    "\n",
    "# Backprop\n",
    "loss.backward()\n",
    "\n",
    "# Update weights\n",
    "weights.data -= .01 * weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "softmax.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bigram array for storage of inputs and targets\n",
    "train_inputs = []\n",
    "train_targets = []\n",
    "\n",
    "\n",
    "# Iterate over every word\n",
    "for word in words:\n",
    "    \n",
    "    # append start and end tokens to word\n",
    "    chst = ['<S>'] + [char for char in word] + ['<E>']\n",
    "    \n",
    "    # Add bigram to training data.\n",
    "    for ch1, ch2 in zip(chst, chst[1:]):\n",
    "        \n",
    "        # add data to training set\n",
    "        train_inputs.append(char_to_int[ch1])\n",
    "        train_targets.append(char_to_int[ch2])\n",
    "        \n",
    "    # Define Stopping point \n",
    "    # no stopping point necessary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_targets = torch.tensor(train_targets)\n",
    "\n",
    "# Initialize training weights radnomly, uniform 0 to 1 exclusive\n",
    "training_weights = torch.rand(28, 28, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training data. \n",
    "train_inputs_enc = F.one_hot(train_inputs, num_classes=28).float()\n",
    "\n",
    "# train_inputs_enc.shape -> 228146 x 28\n",
    "train_targets_enc = F.one_hot(train_targets, num_classes=28).float()\n",
    "# print(train_inputs_enc)\n",
    "# train_inputs\n",
    "# train_targets_enc = F.one_hot(train_targets, num_classes=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs_enc.shape)\n",
    "print(training_weights.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(100):\n",
    "    \n",
    "# Foward pass\n",
    "# Calculate linear layer output\n",
    "logits = train_inputs_enc @ training_weights.T\n",
    "\n",
    "# Apply softmax layer for normalization and conversion to valid pdf\n",
    "softmax = F.softmax(logits, dim=1)\n",
    "\n",
    "# # # store likelihood of data\n",
    "log_lik = softmax[:, train_targets]\n",
    "# # log_lik = softmax[torch.arange(train_inputs.shape[0]), train_targets].log()\n",
    "# neg_log_lik = -log_lik\n",
    "# loss = neg_log_lik\n",
    "\n",
    "# print(f\"K: {k}, Loss: {loss}\")\n",
    "\n",
    "# # Clear weights\n",
    "# training_weights.grad.zero_()\n",
    "\n",
    "# # backward pass\n",
    "# loss.backward()\n",
    "\n",
    "# training_weights.data += .01 * training_weights.grad\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = [1, 2, 3, 4]\n",
    "[0 for _ in range(len(input))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class Params:\n",
    "#     \"\"\"Class representing parameters to a mini Neural Net aka WizNet.\"\"\"\n",
    "    \n",
    "#     activationFunc = {\n",
    "#         \"Sigmoid\": lambda x: 1 / (1 + np.exp(-x)),\n",
    "#         \"ReLU\": lambda x: np.maximum(0, x),\n",
    "#         \"Tanh\": lambda x: np.tanh(x),\n",
    "#     }\n",
    "    \n",
    "#     def __init__(self, value, grad=0, dtype=None):\n",
    "#         \"\"\"\n",
    "#         Initializes a parameter.\n",
    "\n",
    "#         Args:\n",
    "#             value (float or list/np.ndarray): The value of the parameter.\n",
    "#             grad (float or list/np.ndarray, optional): The gradient of the parameter. Default is 0.\n",
    "#             dtype (str, optional): The type of the parameter. Default is None.\n",
    "#         \"\"\"\n",
    "#         self.value = value\n",
    "#         self.grad = grad\n",
    "#         self.type = dtype\n",
    "    \n",
    "#     def __add__(self, biasParam):\n",
    "#         \"\"\"\n",
    "#         Adds two parameters.\n",
    "\n",
    "#         Args:\n",
    "#             biasParam (Params): The bias parameter to add.\n",
    "\n",
    "#         Returns:\n",
    "#             Params: A new Params object with the summed value.\n",
    "#         \"\"\"\n",
    "#         total = self.value + biasParam.value\n",
    "#         return Params(total)\n",
    "    \n",
    "#     def __mul__(self, dataParam):\n",
    "#         \"\"\"\n",
    "#         Multiplies the parameter value with another parameter using dot product.\n",
    "\n",
    "#         Args:\n",
    "#             dataParam (Params): The data parameter to multiply with.\n",
    "\n",
    "#         Returns:\n",
    "#             Params: A new Params object with the resulting value.\n",
    "#         \"\"\"\n",
    "#         total = np.dot(self.value, dataParam.value)\n",
    "#         return Params(total)\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         \"\"\"\n",
    "#         Returns a string representation of the parameter.\n",
    "\n",
    "#         Returns:\n",
    "#             str: A string describing the parameter type, value, and gradient.\n",
    "#         \"\"\"\n",
    "#         return f\"Parameter type: {self.type}, Value: {self.value}, Grad: {self.grad}\"\n",
    "\n",
    "#     def weighted_sum(self, param1, param2):\n",
    "#         \"\"\"\n",
    "#         Calculates the weighted sum of weights, data, and bias parameters.\n",
    "\n",
    "#         Args:\n",
    "#             param1 (Params): The first parameter (e.g., weights).\n",
    "#             param2 (Params): The second parameter (e.g., data).\n",
    "\n",
    "#         Returns:\n",
    "#             Params: A new Params object with the weighted sum.\n",
    "#         \"\"\"\n",
    "#         variables = {\n",
    "#             self.type: self,\n",
    "#             param1.type: param1,\n",
    "#             param2.type: param2\n",
    "#         }\n",
    "        \n",
    "#         weighted_sum = np.dot(variables['weight'].value, variables['data'].value) + variables['bias'].value\n",
    "        \n",
    "#         return Params(weighted_sum, dtype='data')\n",
    "        \n",
    "\n",
    "# class Weights(Params):\n",
    "#     \"\"\"Class representing weights input to a neuron / nn.\"\"\"\n",
    "    \n",
    "#     def __init__(self, value):\n",
    "#         \"\"\"\n",
    "#         Initializes weights parameters to specified value.\n",
    "\n",
    "#         Args:\n",
    "#             value (float or list/np.ndarray): The value of the weights.\n",
    "#         \"\"\"\n",
    "#         super().__init__(value)\n",
    "#         self.type = \"weight\"\n",
    "\n",
    "# class Bias(Params):\n",
    "#     \"\"\"Class representing bias input to a neuron / nn.\"\"\"\n",
    "    \n",
    "#     def __init__(self, value):\n",
    "#         \"\"\"\n",
    "#         Initializes bias parameter to specified value.\n",
    "\n",
    "#         Args:\n",
    "#             value (float or list/np.ndarray): The value of the bias.\n",
    "#         \"\"\"\n",
    "#         super().__init__(value)\n",
    "#         self.type = \"bias\"\n",
    "\n",
    "# class Data(Params):\n",
    "#     \"\"\"Class representing data input to a neuron / nn.\"\"\"\n",
    "    \n",
    "#     def __init__(self, value):\n",
    "#         \"\"\"\n",
    "#         Initializes data parameter to specified value.\n",
    "\n",
    "#         Args:\n",
    "#             value (float or list/np.ndarray): The initial value of the data.\n",
    "#         \"\"\"\n",
    "#         super().__init__(value)  \n",
    "#         self.type = \"data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "class Params:\n",
    "    \"\"\"Class representing parameters to a mini Neural Net aka WizNet.\"\"\"\n",
    "    \n",
    "    activationFunc = {\n",
    "        \"Sigmoid\": lambda x: 1 / (1 + np.exp(-x)),\n",
    "        \"ReLU\": lambda x: np.maximum(0, x),\n",
    "        \"Tanh\": lambda x: np.tanh(x),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, value, grad=0, dtype=None):\n",
    "        \"\"\"\n",
    "        Initializes a parameter.\n",
    "\n",
    "        Args:\n",
    "            value (float or list/np.ndarray): The value of the parameter.\n",
    "            grad (float or list/np.ndarray, optional): The gradient of the parameter. Default is 0.\n",
    "            dtype (str, optional): The type of the parameter. \n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        self.grad = grad\n",
    "        self.type = dtype\n",
    "        self._prev = set()\n",
    "        self._op = None\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Adds two parameters.\n",
    "\n",
    "        Args:\n",
    "            other (Params): The other parameter to add.\n",
    "\n",
    "        Returns:\n",
    "            Params (Data): New Params object with the summed value.\n",
    "        \"\"\"\n",
    "        result = Params(self.value + other.value, dtype='data')\n",
    "        result._prev = {self, other}\n",
    "        result._op = '+'\n",
    "        return result\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Multiplies the parameter value with another parameter using dot product.\n",
    "\n",
    "        Args:\n",
    "            other (Params): The other parameter to multiply with.\n",
    "\n",
    "        Returns:\n",
    "            Params: New Params object with the resulting value.\n",
    "        \"\"\"\n",
    "        result = Params(np.dot(self.value, other.value), dtype='product')\n",
    "        result._prev = {self, other}\n",
    "        result._op = '*'\n",
    "        return result\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the parameter.\n",
    "\n",
    "        Returns:\n",
    "            str: String describing the parameter type, value, and gradient.\n",
    "        \"\"\"\n",
    "        return f\"Parameter type: {self.type}, Value: {self.value}, Grad: {self.grad}\"\n",
    "\n",
    "    def weighted_sum(self, weight, data, bias):\n",
    "        \"\"\"\n",
    "        Calculates the weighted sum of weights, data, and bias parameters.\n",
    "\n",
    "        Args:\n",
    "            weight (Params): The weights parameter.\n",
    "            data (Params): The data parameter.\n",
    "            bias (Params): The bias parameter.\n",
    "\n",
    "        Returns:\n",
    "            Params: New Params object with the weighted sum.\n",
    "        \"\"\"\n",
    "        result = Params(Params.activationFunc[function](self.value), dtype = \"Activation\")\n",
    "        result._prev = {self, bias}\n",
    "        result._op = function\n",
    "        return result\n",
    "        \n",
    "        return weight * data + bias\n",
    "    \n",
    "    def apply_activation(self, function='Sigmoid'):\n",
    "        result = Params(Params.activationFunc[function](self.value), dtype = \"Activation\")\n",
    "        result._prev = {self}\n",
    "        result._op = function\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def backprop(self):\n",
    "        if self._prev:\n",
    "            if self._op == \"+\":\n",
    "                for param in self._prev:\n",
    "                    param.grad = 1 * self.grad  # Accumulate gradients\n",
    "            elif self._op == \"*\":\n",
    "                product = 1\n",
    "                for param in self._prev:\n",
    "                    product *= param.value\n",
    "                for param in self._prev:\n",
    "                    param.grad = self.grad * (product / param.value)  # Accumulate gradients\n",
    "            elif self._op in Params.activationFunc.keys():\n",
    "                if self._op == \"Sigmoid\":\n",
    "                    grad = self.value * (1 - self.value)  # Sigmoid derivative\n",
    "                elif self._op == \"Tanh\":\n",
    "                    grad = 1 - self.value ** 2  # Tanh derivative\n",
    "                elif self._op == \"ReLU\":\n",
    "                    grad = 1 if self.value > 0 else 0  # ReLU derivative\n",
    "                for param in self._prev:\n",
    "                    param.grad = self.grad * grad  # Apply chain rule\n",
    "                    # param.grad = self.grad * grad  # Apply chain rule\n",
    "\n",
    "            for param in self._prev:\n",
    "                param.backprop()\n",
    "\n",
    "                    \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "class Weights(Params):\n",
    "    \"\"\"Class representing weights input to a neuron / nn.\"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        \"\"\"\n",
    "        Initializes weights parameters to specified value.\n",
    "\n",
    "        Args:\n",
    "            value (float or list/np.ndarray): The value of the weights.\n",
    "        \"\"\"\n",
    "        super().__init__(value)\n",
    "        self.type = \"weight\"\n",
    "\n",
    "class Bias(Params):\n",
    "    \"\"\"Class representing bias input to a neuron / nn.\"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        \"\"\"\n",
    "        Initializes bias parameter to specified value.\n",
    "\n",
    "        Args:\n",
    "            value (float or list/np.ndarray): The value of the bias.\n",
    "        \"\"\"\n",
    "        super().__init__(value)\n",
    "        self.type = \"bias\"\n",
    "\n",
    "class Data(Params):\n",
    "    \"\"\"Class representing data input to a neuron / nn.\"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        \"\"\"\n",
    "        Initializes data parameter to specified value.\n",
    "\n",
    "        Args:\n",
    "            value (float or list/np.ndarray): The initial value of the data.\n",
    "        \"\"\"\n",
    "        super().__init__(value)  \n",
    "        self.type = \"data\"\n",
    "\n",
    "\n",
    "# Visualization code form Andrej Karpathy Micrograd\n",
    "# Reference: https://github.com/karpathy/micrograd\n",
    "\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "    \n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "                \n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def format_value(value):\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return np.array2string(value, precision=4, separator=',')\n",
    "    else:\n",
    "        return f\"{value:.4f}\"\n",
    "\n",
    "def draw_dot(root):\n",
    "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})  # LR = left to right\n",
    "    \n",
    "    nodes, edges = trace(root)\n",
    "    # print(nodes, edges)\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        dot.node(name=uid, label=\"{ %s | value %s | grad %.4f }\" % (n.type, format_value(n.value), n.grad), shape='record')\n",
    "        if n._op:\n",
    "            dot.node(name=uid + n._op, label=n._op)\n",
    "            # print(uid, n._op)\n",
    "            dot.edge(uid + n._op, uid)\n",
    "\n",
    "    # print(edges)\n",
    "    for n1, n2 in edges:\n",
    "        print(n2, n2._op)\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "    return dot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Data(22)\n",
    "# b = Weights(.5)\n",
    "# c = Bias(23)\n",
    "# d = a*b + c\n",
    "# e = d.apply_activation(function=\"ReLU\")\n",
    "\n",
    "\n",
    "# e.grad = 2\n",
    "# e.backprop()\n",
    "# draw_dot(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

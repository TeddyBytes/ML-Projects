{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# print(dask.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to parquet files\n",
    "\n",
    "# Paths to save the Parquet files\n",
    "# parquet_dir = \"../../data/processed/\"\n",
    "\n",
    "# # 1. \n",
    "# # Convert pandas DataFrames to Parquet\n",
    "# data_tip = pd.read_json(f\"../../data/raw/yelp_academic_dataset_tip.json\", lines=True)\n",
    "# data_tip.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_tip.parquet\"))\n",
    "\n",
    "# # Convert Dask DataFrames to Parquet\n",
    "# data_businesses = dd.read_json(f\"../../data/raw/yelp_academic_dataset_business.json\", lines=True)\n",
    "# data_businesses.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_business.parquet\"))\n",
    "\n",
    "# data_checkin = dd.read_json(f\"../../data/raw/yelp_academic_dataset_checkin.json\", lines=True)\n",
    "# data_checkin.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_checkin.parquet\"))\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "# data_user = dd.read_json(f\"../../data/raw/yelp_academic_dataset_user.json\", lines=True)\n",
    "# data_user.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_user.parquet\"))\n",
    "\n",
    "# # Read the large JSON file with Dask in chunks and convert to Parquet\n",
    "# data_review = dd.read_json(f\"../../data/raw/yelp_academic_dataset_review.json\", lines=True, blocksize=\"64MB\")\n",
    "# data_review.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_review.parquet\"))\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the blocksize to a smaller value to read a subset of the data\n",
    "data_user = dd.read_json('../../data/raw/yelp_academic_dataset_user.json', lines=True, blocksize=2000000)  # 1MB blocksize\n",
    "\n",
    "# Compute a small sample\n",
    "sample_user_sample = data_user.head(100)  # Adjust the number of rows to read\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Review Data\n",
    "# data_review = dd.read_json(os.path.join(json_dir, \"yelp_academic_dataset_review.json\"), lines=True, blocksize=\"64MB\")\n",
    "# sample_review = data_review.sample(frac=0.1)  # Adjust the fraction as needed\n",
    "# sample_review.to_parquet(os.path.join(parquet_dir, \"yelp_academic_dataset_review_sample.parquet\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Parquet Files\n",
    "\n",
    "data_tip = dd.read_parquet(f\"../../data/processed/yelp_academic_dataset_tip.parquet\")\n",
    "data_businesses = dd.read_parquet(f\"../../data/processed/yelp_academic_dataset_business.parquet/part.0.parquet\")\n",
    "data_checkin = dd.read_parquet(\"../../data/processed/yelp_academic_dataset_checkin.parquet/part.0.parquet\")\n",
    "\n",
    "# Load partial data as jsons\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Set respective indices\n",
    "data_businesses = data_businesses.set_index('business_id')\n",
    "data_checkin = data_checkin.set_index('business_id')\n",
    "\n",
    "# Define a function for date conversion\n",
    "def parse_dates(date_str):\n",
    "    try:\n",
    "        # Split the string if it contains multiple dates\n",
    "        dates = date_str.split(', ')\n",
    "        return pd.to_datetime(dates, format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')\n",
    "    except Exception as e:\n",
    "        return pd.NaT\n",
    "\n",
    "# Apply the function with meta argument\n",
    "data_checkin['date'] = data_checkin['date'].apply(\n",
    "    parse_dates, \n",
    "    meta=('x', 'datetime64[ns]')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Compute to view the result\n",
    "# result_businesses = data_businesses.compute()\n",
    "# result_checkin = data_checkin.compute()\n",
    "\n",
    "\n",
    "# print(result_businesses.head())\n",
    "# print(result_checkin.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(data_tip['business_id'].nunique().compute())\n",
    "# print(data_tip['user_id'].nunique().compute())\n",
    "# print(data_tip.shape[0].compute())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_user_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39 entries, 0 to 38\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             39 non-null     string \n",
      " 1   name                39 non-null     string \n",
      " 2   review_count        39 non-null     int64  \n",
      " 3   yelping_since       39 non-null     string \n",
      " 4   useful              39 non-null     int64  \n",
      " 5   funny               39 non-null     int64  \n",
      " 6   cool                39 non-null     int64  \n",
      " 7   elite               39 non-null     string \n",
      " 8   friends             39 non-null     string \n",
      " 9   fans                39 non-null     int64  \n",
      " 10  average_stars       39 non-null     float64\n",
      " 11  compliment_hot      39 non-null     int64  \n",
      " 12  compliment_more     39 non-null     int64  \n",
      " 13  compliment_profile  39 non-null     int64  \n",
      " 14  compliment_cute     39 non-null     int64  \n",
      " 15  compliment_list     39 non-null     int64  \n",
      " 16  compliment_note     39 non-null     int64  \n",
      " 17  compliment_plain    39 non-null     int64  \n",
      " 18  compliment_cool     39 non-null     int64  \n",
      " 19  compliment_funny    39 non-null     int64  \n",
      " 20  compliment_writer   39 non-null     int64  \n",
      " 21  compliment_photos   39 non-null     int64  \n",
      "dtypes: float64(1), int64(16), string(5)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "sample_user_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             84 non-null     string \n",
      " 1   name                84 non-null     string \n",
      " 2   review_count        84 non-null     int64  \n",
      " 3   yelping_since       84 non-null     string \n",
      " 4   useful              84 non-null     int64  \n",
      " 5   funny               84 non-null     int64  \n",
      " 6   cool                84 non-null     int64  \n",
      " 7   elite               84 non-null     string \n",
      " 8   friends             84 non-null     string \n",
      " 9   fans                84 non-null     int64  \n",
      " 10  average_stars       84 non-null     float64\n",
      " 11  compliment_hot      84 non-null     int64  \n",
      " 12  compliment_more     84 non-null     int64  \n",
      " 13  compliment_profile  84 non-null     int64  \n",
      " 14  compliment_cute     84 non-null     int64  \n",
      " 15  compliment_list     84 non-null     int64  \n",
      " 16  compliment_note     84 non-null     int64  \n",
      " 17  compliment_plain    84 non-null     int64  \n",
      " 18  compliment_cool     84 non-null     int64  \n",
      " 19  compliment_funny    84 non-null     int64  \n",
      " 20  compliment_writer   84 non-null     int64  \n",
      " 21  compliment_photos   84 non-null     int64  \n",
      "dtypes: float64(1), int64(16), string(5)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "sample_user_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

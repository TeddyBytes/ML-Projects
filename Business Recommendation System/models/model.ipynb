{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewaudley/Documents/Machine Learning Projects/Business Recommendation System/brs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data processing and numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and recommendation libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# MLflow for experiment tracking\n",
    "import mlflow\n",
    "import wandb\n",
    "\n",
    "# IPython for displaying outputs\n",
    "from IPython.display import display\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split data once - no temporal features\n",
    "# train, temp = spark_df.randomSplit([0.75, 0.25], seed=42)\n",
    "# val, test = temp.randomSplit([.15, .10], seed=42)\n",
    "# # \n",
    "\n",
    "# # define file paths (relative to the current directory)\n",
    "# model_data_path = \"../../data/interim/\"\n",
    "\n",
    "# # save each DataFrame in parquet format\n",
    "# train.write.parquet(os.path.join(model_data_path, f\"train_set.parquet\"), mode='overwrite')\n",
    "# val.write.parquet(os.path.join(model_data_path, f\"val_set.parquet\"), mode='overwrite')\n",
    "# test.write.parquet(os.path.join(model_data_path, f\"test_set.parquet\"), mode='overwrite')\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# ========================================\n",
    "# Open sessions for necessary packages\n",
    "# ========================================\n",
    "# spark = None\n",
    "\n",
    "# def open_session(close=False):\n",
    "#     global spark  # \n",
    "#     if not close:\n",
    "#         if spark is None or spark.sparkContext is None:\n",
    "#             spark = SparkSession.builder \\\n",
    "#                 .appName(\"ALS in Spark\") \\\n",
    "#                 .getOrCreate()\n",
    "#             # set up MLflow (only needs to be done once)\n",
    "#     else:\n",
    "#         if spark is not None:\n",
    "#             spark.stop()\n",
    "#             spark = None\n",
    "            \n",
    "# # open_session()\n",
    "# open_session(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA\n",
    "# model_data_path = \"../data/interim/\"\n",
    "\n",
    "# train = spark.read.parquet(os.path.join(model_data_path, \"train_set.parquet\")).toPandas()\n",
    "# val = spark.read.parquet(os.path.join(model_data_path, \"val_set.parquet\")).toPandas()\n",
    "# test = spark.read.parquet(os.path.join(model_data_path, \"test_set.parquet\")).toPandas()\n",
    "\n",
    "# train.repartition(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define PySpark ALS model\n",
    "# als = ALS(\n",
    "#     userCol=\"user_index\",\n",
    "#     itemCol=\"bus_index\",\n",
    "#     ratingCol=\"rating\",\n",
    "#     coldStartStrategy=\"drop\"\n",
    "# )\n",
    "\n",
    "\n",
    "# # # Grid search through hyperparameters\n",
    "# # paramGrid = (ParamGridBuilder()\n",
    "# #              .addGrid(als.rank, [5, 10, 15])\n",
    "# #              .addGrid(als.maxIter, [5, 10, 20])\n",
    "# #              .addGrid(als.regParam, [0.01, 0.1, 0.5])\n",
    "# #              .build())\n",
    "\n",
    "# # define criterion\n",
    "# evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "# # define cross-validation w simple grid\n",
    "# crossval = CrossValidator(\n",
    "#     estimator=als,\n",
    "#     evaluator=evaluator,\n",
    "#     estimatorParamMaps=paramGrid,\n",
    "#     numFolds=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd = train.rdd\n",
    "# partitions = rdd.glom().collect()\n",
    "# for index, partition in enumerate(partitions):\n",
    "#     print(f\"Partition {index} contains {len(partition)} rows.\")\n",
    "#     if len(partition) > 0:\n",
    "#         print(f\"Sample data from partition {index}: {partition[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# open log \n",
    "# mlflow.set_experiment(\"ALS_Hyperparameter_Tuning\")\n",
    "\n",
    "# log results\n",
    "# with mlflow.start_run():\n",
    "    \n",
    "    # fit model using cross-validation\n",
    "    # cv_model = crossval.fit(train)\n",
    "    \n",
    "    # Log the best model\n",
    "    # best_model = cv_model.bestModel\n",
    "    # mlflow.spark.log_model(best_model, \"best_model\")\n",
    "    \n",
    "    # # Log metrics and model parameters for each parameter combination\n",
    "    # for param_map, metric in zip(crossval.getEstimatorParamMaps(), cv_model.avgMetrics):\n",
    "    #     rank = param_map[als.rank]\n",
    "    #     regParam = param_map[als.regParam]\n",
    "    #     maxIter = param_map[als.maxIter]\n",
    "        \n",
    "    #     mlflow.log_param(\"rank\", rank)\n",
    "    #     mlflow.log_param(\"regParam\", regParam)\n",
    "    #     mlflow.log_param(\"maxIter\", maxIter)\n",
    "    #     mlflow.log_metric(\"validation_rmse\", metric)\n",
    "\n",
    "    # # Log validation scores\n",
    "    # validation_predictions = best_model.transform(val)\n",
    "    # validation_rmse = evaluator.evaluate(validation_predictions)\n",
    "    # mlflow.log_metric(\"validation_rmse\", validation_rmse)\n",
    "\n",
    "\n",
    "# # Log test metrics (optional, after final model selection)\n",
    "# test_predictions = best_model.transform(test)\n",
    "# test_rmse = evaluator.evaluate(test_predictions)\n",
    "# mlflow.log_metric(\"test_rmse\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "final_df_path = \"../data/processed/Final Dataframes/final_df.parquet\"\n",
    "tensor_path = \"../data/processed/Final Tensors/\"\n",
    "\n",
    "\n",
    "# # Check if Mac GPU is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Check if nvidia gpu is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_data(dataframe, test_size=0.2, random_state=42):\n",
    "    # split data\n",
    "    train_df, temp_df = train_test_split(dataframe, test_size=test_size, random_state=random_state)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=.5, random_state=random_state)\n",
    "\n",
    "    # create datasets\n",
    "    train_dataset = CFDataset(train_df)\n",
    "    val_dataset = CFDataset(val_df)\n",
    "    test_dataset = CFDataset(test_df)\n",
    "\n",
    "    # save datasets\n",
    "    torch.save(train_dataset, os.path.join(tensor_path,'train_dataset.pt'))\n",
    "    torch.save(val_dataset, os.path.join(tensor_path,'val_dataset.pt'))\n",
    "    torch.save(test_dataset, os.path.join(tensor_path,'test_dataset.pt'))\n",
    "\n",
    "    print(\"Datasets have been split and saved.\")\n",
    "\n",
    "def load_datasets(path):\n",
    "    train_dataset = torch.load(os.path.join(path,'train_dataset.pt'))\n",
    "    val_dataset = torch.load(os.path.join(path,'val_dataset.pt'))\n",
    "    test_dataset = torch.load(os.path.join(path,'test_dataset.pt'))\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "# df = pd.read_parquet(final_df_path)\n",
    "\n",
    "# split_and_save_data(df)\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset, val_dataset, test_dataset = load_datasets(tensor_path)\n",
    "\n",
    "# print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "# print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "# print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3513735"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features['user_id'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': tensor([135044, 251524, 160163,  ...,  84981,  69299, 141271]),\n",
       " 'business_id': tensor([ 74868,  97998,  19175,  ...,  14868,  30678, 135453]),\n",
       " 'city_id': tensor([62, 33, 81,  ...,  3,  3,  2]),\n",
       " 'state_id': tensor([7, 5, 1,  ..., 3, 3, 2]),\n",
       " 'region_id': tensor([2, 6, 4,  ..., 0, 0, 3]),\n",
       " 'dotw': tensor([6, 1, 2,  ..., 0, 3, 5]),\n",
       " 'doty': tensor([357, 136, 279,  ..., 261, 209, 115]),\n",
       " 'pca_features': tensor([[ 2.7052, -0.8092, -0.8594, -0.7496,  0.4360],\n",
       "         [ 0.7773,  1.0229, -1.2422,  0.2214,  1.0620],\n",
       "         [-0.6204,  0.8865, -0.5544,  2.0033,  0.4713],\n",
       "         ...,\n",
       "         [ 1.2921,  0.1585, -0.0708,  0.7642,  0.6987],\n",
       "         [ 2.4021,  0.7214, -0.7895,  0.6848,  0.4224],\n",
       "         [ 0.8602,  0.6749,  0.1199,  1.0643, -0.9290]]),\n",
       " 'tokens': tensor([[ 2035,  2115,  5088,  ..., 21849,  7600, 28663],\n",
       "         [ 1045,  2562,  4531,  ...,  2000,  7370,  2011],\n",
       "         [ 2057,  2245,  2057,  ...,  2183,  2220,  2000],\n",
       "         ...,\n",
       "         [ 6887,  2080,  3492,  ...,  2028,  2518,  6887],\n",
       "         [ 1045,  3030,  2011,  ...,  2034,  2051,  7483],\n",
       "         [ 2307,  2005,  3407,  ..., 11937, 21756,  2021]]),\n",
       " 'categories': tensor([[  11,  622,  941,  ...,    0,    0,    0],\n",
       "         [1116,  562,  351,  ...,    0,    0,    0],\n",
       "         [ 539,   33, 1034,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 421,  351,    0,  ...,    0,    0,    0],\n",
       "         [1223,  562, 1116,  ...,    0,    0,    0],\n",
       "         [ 239,  196,  539,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 287116\n",
      "Number of unique business's : 148523\n"
     ]
    }
   ],
   "source": [
    "# Concat user and business data into one tensor\n",
    "total_user_ids = torch.concat((train_dataset.features['user_id'],\n",
    "                               val_dataset.features['user_id'],\n",
    "                               test_dataset.features['user_id']), dim=0)\n",
    "total_business_ids = torch.concat((train_dataset.features['business_id'],\n",
    "                                    val_dataset.features['business_id'],\n",
    "                                    test_dataset.features['business_id']), dim=0)\n",
    "\n",
    "# get number of unique entities\n",
    "num_unique_users = torch.unique(total_user_ids).shape[0] \n",
    "num_unique_bus = torch.unique(total_business_ids).shape[0]\n",
    "\n",
    "# output findings\n",
    "print(f\"Number of unique users: {num_unique_users}\")\n",
    "print(f\"Number of unique business's : {num_unique_bus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.features = {\n",
    "            'user_id': torch.tensor(dataframe['user_num_id'].values, dtype=torch.long),\n",
    "            'business_id': torch.tensor(dataframe['business_num_id'].values, dtype=torch.long),\n",
    "            'city_id': torch.tensor(dataframe['city_code'].values, dtype=torch.long),\n",
    "            'state_id': torch.tensor(dataframe['state_code'].values, dtype=torch.long),\n",
    "            'region_id': torch.tensor(dataframe['region_code'].values, dtype=torch.long),\n",
    "            'dotw': torch.tensor(dataframe['day_of_week'].values, dtype=torch.long),\n",
    "            'doty': torch.tensor(dataframe['day_of_year'].values, dtype=torch.long),\n",
    "            # 'numerical_features': torch.tensor(dataframe[['user_avg_rating_norm', \n",
    "            #                                               'bus_avg_rating_norm', \n",
    "            #                                               'log_business_review_count_norm', \n",
    "            #                                               'log_user_review_count_norm', \n",
    "            #                                               'years_yelp_member_norm', \n",
    "            #                                               'years_since_review_norm']]\n",
    "            #                                    .values,\n",
    "            #                                    dtype=torch.float),\n",
    "            'pca_features': torch.tensor(dataframe[['pca_1', 'pca_2', 'pca_3', \n",
    "                                                    'pca_4', 'pca_5']].values, dtype=torch.float),\n",
    "            'tokens': torch.tensor(dataframe['tokens'].tolist(), dtype=torch.long),\n",
    "            'categories' : torch.tensor(dataframe['categories_enc'].tolist(), dtype=torch.long)\n",
    "        }\n",
    "        self.target = torch.tensor(dataframe['mean_centered_rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.features.items()}, self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFmodel(nn.Module):\n",
    "    def __init__(self, vocab_size=30522, rank=32, num_users=287116, num_bus=148523, num_city=1273, \n",
    "                 num_regions=11, num_states=50, token_length=10, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.token_length = token_length\n",
    "\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, rank)\n",
    "        self.bus_emb = nn.Embedding(num_bus, rank)\n",
    "        self.city_emb = nn.Embedding(num_city, rank)\n",
    "        self.state_emb = nn.Embedding(num_states, rank)\n",
    "        self.region_emb = nn.Embedding(num_regions, rank)\n",
    "        self.dotw_emb = nn.Embedding(7, rank)\n",
    "        self.doty_emb = nn.Embedding(367, rank)\n",
    "        self.token_emb = nn.Embedding(vocab_size, rank)\n",
    "\n",
    "        # Layer for numerical features\n",
    "        self.numerical_layer = nn.Sequential(\n",
    "            nn.Linear(6, rank),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(rank)\n",
    "        )\n",
    "\n",
    "        # Multi-head attention for combining embeddings\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=rank, num_heads=num_heads)\n",
    "        \n",
    "        # Final layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(rank, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        # Process embeddings\n",
    "        user_emb = self.user_emb(kwargs['user_id']).unsqueeze(0)\n",
    "        bus_emb = self.bus_emb(kwargs['business_id']).unsqueeze(0)\n",
    "        city_emb = self.city_emb(kwargs['city_id']).unsqueeze(0)\n",
    "        state_emb = self.state_emb(kwargs['state_id']).unsqueeze(0)\n",
    "        region_emb = self.region_emb(kwargs['region_id']).unsqueeze(0)\n",
    "        dotw_emb = self.dotw_emb(kwargs['dotw']).unsqueeze(0)\n",
    "        doty_emb = self.doty_emb(kwargs['doty']).unsqueeze(0)\n",
    "        \n",
    "        # Process numerical features\n",
    "        numerical = self.numerical_layer(kwargs['numerical_features']).unsqueeze(0)\n",
    "        \n",
    "        # Process tokens (reviews)\n",
    "        tokens_emb = self.token_emb(kwargs['tokens']).mean(dim=1).unsqueeze(0)  # Average pooling\n",
    "        \n",
    "        # Combine all features using multi-head attention\n",
    "        combined_features = torch.cat([\n",
    "            user_emb, bus_emb, city_emb, state_emb, region_emb, \n",
    "            dotw_emb, doty_emb, numerical, tokens_emb\n",
    "        ], dim=0)\n",
    "        \n",
    "        attn_output, _ = self.multihead_attn(combined_features, combined_features, combined_features)\n",
    "        \n",
    "        # Average the attention output\n",
    "        final_representation = attn_output.mean(dim=0)\n",
    "        \n",
    "        # Pass through final layers\n",
    "        result = self.fc_layers(final_representation)\n",
    "        \n",
    "        return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CFmodel(\n",
       "  (user_emb): Embedding(287116, 32)\n",
       "  (bus_emb): Embedding(148523, 32)\n",
       "  (city_emb): Embedding(1273, 32)\n",
       "  (state_emb): Embedding(50, 32)\n",
       "  (region_emb): Embedding(11, 32)\n",
       "  (dotw_emb): Embedding(7, 32)\n",
       "  (doty_emb): Embedding(367, 32)\n",
       "  (token_emb): Embedding(30522, 32)\n",
       "  (numerical_layer): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (multihead_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Hyperparameters\n",
    "rank = 32\n",
    "\n",
    "\n",
    "# Model / Optimizer Information \n",
    "batch_size = 64\n",
    "lr = .001\n",
    "dataset=\"yelp\"\n",
    "num_epochs = 1\n",
    "betas = (0.9, 0.999)\n",
    "eps=1e-08\n",
    "weight_decay=.01 \n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CFDataset(train)\n",
    "val_dataset = CFDataset(val)\n",
    "test_dataset = CFDataset(test)\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "model = CFmodel()\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model and define optimization\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),    # Parameters of the model to optimize\n",
    "    lr=lr,              # Learning rate (default is 0.001)\n",
    "    betas=betas,    # Coefficients for computing running averages of gradient and its square\n",
    "    eps=eps,             # Term added to the denominator to improve numerical stability\n",
    "    weight_decay=weight_decay       # Weight decay (L2 penalty)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mteddybytes\u001b[0m (\u001b[33mteddybytesorg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/matthewaudley/Documents/Machine Learning Projects/Business Recommendation System/models/wandb/run-20240917_023841-gszr8jl0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0' target=\"_blank\">good-wildflower-20</a></strong> to <a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project' target=\"_blank\">https://wandb.ai/teddybytesorg/hyperparameter_tuning_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0' target=\"_blank\">https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3d47bc5f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"hyperparameter_tuning_project\", config={\n",
    "    # \"hidden_layers\": model.hidden_layers,\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"CF\",\n",
    "    \"dataset\": \"Yelp\",\n",
    "    \"betas\": betas,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"rank\": rank\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: v.to(device) for k, v in data.items()}\n",
    "    return data.to(device)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gszr8jl0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-wildflower-20</strong> at: <a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0' target=\"_blank\">https://wandb.ai/teddybytesorg/hyperparameter_tuning_project/runs/gszr8jl0</a><br/> View project at: <a href='https://wandb.ai/teddybytesorg/hyperparameter_tuning_project' target=\"_blank\">https://wandb.ai/teddybytesorg/hyperparameter_tuning_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240917_023841-gszr8jl0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gszr8jl0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/matthewaudley/Documents/Machine Learning Projects/Business Recommendation System/models/wandb/run-20240917_023850-ipzfkops</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teddybytesorg/initial%20modeling/runs/ipzfkops' target=\"_blank\">jumping-resonance-4</a></strong> to <a href='https://wandb.ai/teddybytesorg/initial%20modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teddybytesorg/initial%20modeling' target=\"_blank\">https://wandb.ai/teddybytesorg/initial%20modeling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teddybytesorg/initial%20modeling/runs/ipzfkops' target=\"_blank\">https://wandb.ai/teddybytesorg/initial%20modeling/runs/ipzfkops</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 0, Train Loss: 1.9933, Val Loss: 1.4511\n",
      "Epoch: 0, Iter: 250, Train Loss: 1.3015, Val Loss: 1.4440\n",
      "Epoch: 0, Iter: 500, Train Loss: 1.4819, Val Loss: 1.4430\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.profiler\n",
    "import wandb\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"initial modeling\")  # Specify your project name\n",
    "\n",
    "# Initialize TensorBoard\n",
    "tb_writer = SummaryWriter('runs/experiment_1')\n",
    "\n",
    "# Initialize W&B to watch the model\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# Profiling setup\n",
    "profiler = torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True\n",
    ")\n",
    "\n",
    "# Training loop with profiling\n",
    "with profiler:\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        for features, target in train_loader:\n",
    "            features = to_device(features, device)\n",
    "            target = to_device(target, device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(**features)\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log gradient norms for each layer\n",
    "            total_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)  # Compute L2 norm\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "\n",
    "            total_norm = total_norm ** 0.5\n",
    "\n",
    "            # Log to TensorBoard\n",
    "            tb_writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + num_iter)\n",
    "            tb_writer.add_scalar('Gradient Norms', total_norm, epoch * len(train_loader) + num_iter)\n",
    "\n",
    "            # Log to W&B\n",
    "            wandb.log({\n",
    "                'epoch': epoch,\n",
    "                'iteration': num_iter,\n",
    "                'train_loss': loss.item(),\n",
    "                'gradient_norms': total_norm\n",
    "            })\n",
    "\n",
    "            if num_iter % 250 == 0:\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_features, val_target in val_loader:\n",
    "                        val_features = to_device(val_features, device)\n",
    "                        val_target = to_device(val_target, device)\n",
    "\n",
    "                        val_pred = model(**val_features)\n",
    "                        val_loss += criterion(val_pred, val_target).item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "\n",
    "                # Log metrics to TensorBoard\n",
    "                tb_writer.add_scalar('Loss/validation', val_loss, epoch * len(train_loader) + num_iter)\n",
    "                \n",
    "                # Log metrics to W&B\n",
    "                wandb.log({\n",
    "                    'epoch': epoch,\n",
    "                    'iteration': num_iter,\n",
    "                    'train_loss': loss.item(),\n",
    "                    'val_loss': val_loss\n",
    "                })\n",
    "\n",
    "                print(f\"Epoch: {epoch}, Iter: {num_iter}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            num_iter += 1\n",
    "\n",
    "# Finish profiling and print results\n",
    "profiler.stop()\n",
    "print(profiler.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "# Save the model and log as an artifact\n",
    "model_path = \"model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Log the model as an artifact in W&B\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file(model_path)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# Finish the W&B run\n",
    "wandb.finish()\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "tb_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
